{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # To use regex operations\n",
    "# from time import sleep\n",
    "from bs4 import BeautifulSoup #To parse response text using the html parser\n",
    "import requests #To make request from the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords', quiet=True) #stopwords\n",
    "nltk.download('wordnet', quiet=True) #\n",
    "from newspaper import Article #To read the content of a webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim #Gensim is an open-source library for unsupervised topic modeling and natural language processing\n",
    "from gensim.models.ldamulticore import LdaMulticore # for multipreprocessing\n",
    "from gensim import corpora, models #\n",
    "from gensim.corpora import Dictionary\n",
    "import pyLDAvis.gensim #for visualization\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "\n",
    "# from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vishal waghmare\\3d objects\\vscode_codes\\github\\pandas\\careerninja\\careerninja\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using Yahoo Search Engine for WebScrapping\n",
    "template = 'https://in.search.yahoo.com/search;_ylt=AwrwIQa9FFJgmlQA7hq7HAx.;_ylu=Y29sbwNzZzMEcG9zAzEEdnRpZAMEc2VjA3BpdnM-?p={}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter ypur main query : chanda india\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Enter your main query : \")\n",
    "url = template.format(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make the get request, we first set the request headers\n",
    "headers = {\n",
    "    'accept': '*/*',\n",
    "    'accept-encoding': 'gzip, deflate, br',\n",
    "    'accept-language': 'en-US,en;q=0.9',\n",
    "    'referer': 'https://www.google.com',\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cards = soup.find_all('div', 'NewsArticle')\n",
    "cards = soup.find_all('div', 'algo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All the articles result currently in the html form\n",
    "len(cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get the headline of the article and its url\n",
    "def get_article(card):\n",
    "    '''Extract article information from the raw html'''\n",
    "#     headline = card.find('h4', 's-title').text\n",
    "    headline = card.find('h3', 'title').text\n",
    "    raw_link = card.find('a').get('href')\n",
    "    unquoted_link = requests.utils.unquote(raw_link)\n",
    "    pattern = re.compile(r'RU=(.+)\\/RK')\n",
    "    clean_link = re.search(pattern, unquoted_link).group(1)\n",
    "    article = [headline, clean_link]\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the headline and url for every article on the first page in the articles list\n",
    "articles = []\n",
    "links = set()\n",
    "for card in cards:\n",
    "    article = get_article(card)\n",
    "    link = article[-1]\n",
    "    if not link in links:\n",
    "        links.add(link)\n",
    "        articles.append(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class top_article:\n",
    "    def __init__(self, article_name, article_link):\n",
    "        '''To set article name and article link for every article'''\n",
    "        self.article_name = article_name\n",
    "        self.article_link = article_link\n",
    "\n",
    "    def get_uncleaned_webcontent(self):\n",
    "        '''To get the cleaned web article from all the web articles'''\n",
    "        \n",
    "        article = Article(self.article_link)\n",
    "        \n",
    "        try :\n",
    "            article.download()\n",
    "            article.parse()\n",
    "            nltk.download('punkt', quiet = True)\n",
    "            article.nlp()\n",
    "            \n",
    "            if len(article.text) > 100:\n",
    "                '''Taking only the articles with total text length greater than 100'''\n",
    "                self.article_content = article.text\n",
    "            else:\n",
    "                self.article_content = \"It is invalid. Go for next\"\n",
    "            \n",
    "        except:\n",
    "            '''Exception if the article does not have permission to get scrapped'''\n",
    "            self.article_content = \"It is invalid. Go for next\"\n",
    "        \n",
    "        \n",
    "    def clean(self):\n",
    "        '''\n",
    "        Splitting the data\n",
    "        Removing the punctuations\n",
    "        Lemmatization : making sure that words like spectacle/spectacles are considered same\n",
    "        '''\n",
    "        stop_free = ' '.join([word for word in self.article_content.lower().split() if word not in stop])\n",
    "        punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "        normalized = ' '.join([lemma.lemmatize(word) for word in punc_free.split()])\n",
    "        self.article_cleaned =  normalized.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dictionary(bag_of_words):\n",
    "    '''Make a single dictionary of the words from top 5 articles'''\n",
    "    dictionary = corpora.Dictionary(bag_of_words)\n",
    "    return dictionary\n",
    "\n",
    "def make_doc_term_matrix(dictionary, bag_of_words):\n",
    "    '''\n",
    "    A matrix which stores the occurence and frequency of each word from the bag of words\n",
    "    As we have 5 articles, this matrix will have 5 rows\n",
    "    '''\n",
    "    doc_term_matrix = [dictionary.doc2bow(doc) for doc in bag_of_words]\n",
    "    return doc_term_matrix\n",
    "\n",
    "def build_lda_model(dictionary, doc_term_matrix, lda, num_topics):\n",
    "    '''Training the model by passing the hyperparameters'''\n",
    "    lda_model = lda(doc_term_matrix, num_topics = num_topics, id2word=dictionary, passes=50, minimum_probability=0)\n",
    "    return lda_model\n",
    "\n",
    "def print_topic_clusters(lda_model, num_topics):\n",
    "    '''\n",
    "    Print the clusters of selected number of topics\n",
    "    Each cluster shows the relevant keywords associated with that cluster using which we can determine the topic of that cluster\n",
    "    '''\n",
    "    print('\\033[1m')\n",
    "    print(\"\\nKeywords/Topics/Tags for the articles\\n\")\n",
    "    print('\\033[0m')\n",
    "    keywords_and_probs = lda_model.print_topics(num_topics=num_topics)\n",
    "    keywords_only = []\n",
    "    for i in keywords_and_probs:\n",
    "        '''Original output contains the probability along with the keywords. Here we are trying to extract only the keywords'''\n",
    "        keywords_only.append(re.findall(r'\"(.*?)\"', i[1]))\n",
    "    for i, cluster_keywords in enumerate(keywords_only):\n",
    "        '''We print the cluster number and the keywords associated with that cluster'''\n",
    "        print(\"Cluster\",i+1,cluster_keywords)\n",
    "\n",
    "def build_lda_display(lda_model, doc_term_matrix, dictionary):\n",
    "    '''Here we build the lda_display object which helps us to visualize our results'''\n",
    "    lda_display = pyLDAvis.gensim.prepare(lda_model, doc_term_matrix, dictionary, sort_topics = False, mds='mmds')\n",
    "    return lda_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of topics we want to get(recommended less than 5) :  3\n",
      "\n",
      "Please wait...\n",
      "\n",
      "Top 5 articles are....\n",
      "https://en.wikipedia.org/wiki/Komodo_dragon\n",
      "https://www.britannica.com/animal/Komodo-dragon\n",
      "https://www.nationalgeographic.com/animals/reptiles/facts/komodo-dragon\n",
      "https://animalcorner.org/animals/komodo-dragon/\n",
      "https://theculturetrip.com/asia/indonesia/articles/11-facts-komodo-dragon-indonesias-national-animal/\n",
      "\n",
      "Building the clusters of topics....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:sklearn not present, switch to PCoA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "Keywords/Topics/Tags for the articles\n",
      "\n",
      "\u001b[0m\n",
      "Cluster 1 ['komodo', 'dragon', '–', 'foot', 'lizard', 'large', 'also', '3', 'eat', 'able']\n",
      "Cluster 2 ['komodo', 'dragon', 'komodos', 'female', 'island', 'also', 'year', 'male', 'foot', 'venom']\n",
      "Cluster 3 ['komodo', 'dragon', 'may', 'island', 'egg', 'prey', 'male', 'human', 'two', 'zoo']\n"
     ]
    }
   ],
   "source": [
    "top_articles = []\n",
    "for article in articles:\n",
    "    '''Getting all articles obtained from the search engine. This articles are obtained on the 1st page'''\n",
    "    top_articles.append(top_article(article[0], article[1]))\n",
    "\n",
    "# Initializing the model object\n",
    "lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "\n",
    "# User input for the number of topics would we like to achieve\n",
    "num_topics = int(input(\"Enter the number of topics we want to get(recommended less than 5) :  \"))\n",
    "print(\"\\nPlease wait...\")\n",
    "\n",
    "\n",
    "count = 0\n",
    "valid_top_articles = []\n",
    "for num, article in enumerate(top_articles):\n",
    "    if count >= 5:\n",
    "        # Inorder to get the top 5 articles\n",
    "        break\n",
    "    article.get_uncleaned_webcontent() #Getting the data for every top 5 article\n",
    "    if article.article_content == \"It is invalid. Go for next\":\n",
    "        continue\n",
    "    count = count + 1\n",
    "    article.clean() #Cleaning the the data of every top 5 articles\n",
    "    valid_top_articles.append(article)\n",
    "\n",
    "print(\"\\nTop 5 articles are....\")\n",
    "bag_of_words = []\n",
    "for num, article in enumerate(valid_top_articles):\n",
    "    '''Printing the url for top 5 articles and creating a bag of words from all of them'''\n",
    "    print(article.article_link)\n",
    "    bag_of_words.append(article.article_cleaned)\n",
    "\n",
    "dictionary = make_dictionary(bag_of_words) #Making a dcitionary from the bag of words\n",
    "doc_term_matrix = make_doc_term_matrix(dictionary, bag_of_words) #creating a matrix\n",
    "\n",
    "print(\"\\nBuilding the clusters of topics....\")\n",
    "lda_model = build_lda_model(dictionary, doc_term_matrix, lda, num_topics) #training the model\n",
    "\n",
    "print_topic_clusters(lda_model, num_topics) #printing the cluster results\n",
    "lda_display = build_lda_display(lda_model, doc_term_matrix, dictionary) #building the object capable to show visualization of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el2464423679823261927119557550\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el2464423679823261927119557550_data = {\"mdsDat\": {\"x\": [0.018979007117041563, -0.07184947578170112, 0.05287046866465955], \"y\": [-0.0466049003104427, 0.01266443946726779, 0.03394046084317486], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [12.15892310252847, 19.388379037388948, 68.45269786008258]}, \"tinfo\": {\"Term\": [\"komodo\", \"dragon\", \"komodos\", \"\\u2013\", \"female\", \"also\", \"year\", \"foot\", \"may\", \"large\", \"lizard\", \"eat\", \"water\", \"3\", \"able\", \"male\", \"young\", \"metre\", \"around\", \"use\", \"venom\", \"insect\", \"behaviour\", \"tongue\", \"tail\", \"head\", \"although\", \"food\", \"animal\", \"predator\", \"\\u2013\", \"kilometre\", \"dangerous\", \"support\", \"centimetre\", \"shaded\", \"dosed\", \"2\", \"cannot\", \"4000\", \"5000\", \"985\", \"enough\", \"occurring\", \"season\", \"abundant\", \"drinking\", \"taking\", \"safety\", \"7\", \"deeplyforked\", \"destruction\", \"strictly\", \"mediumlarge\", \"knock\", \"stocky\", \"65\", \"advertisement\", \"smelling\", \"particularly\", \"insect\", \"behaviour\", \"kilogram\", \"plaque\", \"throat\", \"25\", \"dragon\", \"komodo\", \"3\", \"able\", \"mile\", \"per\", \"foot\", \"tail\", \"large\", \"eat\", \"use\", \"water\", \"metre\", \"lizard\", \"hour\", \"megapode\", \"detect\", \"capable\", \"ear\", \"sensory\", \"form\", \"tongue\", \"also\", \"head\", \"year\", \"young\", \"may\", \"egg\", \"although\", \"around\", \"animal\", \"human\", \"prey\", \"pound\", \"length\", \"carrion\", \"myth\", \"massive\", \"ancient\", \"old\", \"home\", \"meter\", \"beast\", \"truth\", \"sign\", \"kraken\", \"fact\", \"cover\", \"swim\", \"and\", \"least\", \"appetite\", \"younger\", \"attributed\", \"clear\", \"asexually\", \"avid\", \"rely\", \"whether\", \"give\", \"feces\", \"inhabit\", \"they\\u2019re\", \"mate\", \"established\", \"komodos\", \"venom\", \"komodo\", \"female\", \"dragon\", \"reproduce\", \"protect\", \"year\", \"also\", \"food\", \"indonesia\", \"habitat\", \"male\", \"island\", \"found\", \"foot\", \"around\", \"avoid\", \"smell\", \"30\", \"known\", \"national\", \"local\", \"taste\", \"size\", \"animal\", \"one\", \"lizard\", \"prey\", \"however\", \"10\", \"victim\", \"reproduction\", \"largest\", \"zoo\", \"specimen\", \"become\", \"ft\", \"first\", \"make\", \"habit\", \"two\", \"protein\", \"london\", \"expedition\", \"auffenberg\", \"scientist\", \"behavior\", \"natural\", \"researcher\", \"osteoderms\", \"period\", \"produced\", \"attack\", \"monitor\", \"case\", \"could\", \"attempt\", \"would\", \"according\", \"observation\", \"bronstein\", \"observed\", \"exhibit\", \"may\", \"chromosome\", \"several\", \"mouth\", \"egg\", \"individual\", \"70\", \"laid\", \"komodo\", \"dragon\", \"prey\", \"bite\", \"island\", \"human\", \"adult\", \"study\", \"male\", \"one\", \"live\", \"wild\", \"long\", \"specie\", \"female\", \"size\", \"varanus\", \"lizard\", \"animal\", \"although\", \"also\", \"year\", \"large\"], \"Freq\": [153.0, 141.0, 12.0, 5.0, 18.0, 17.0, 15.0, 10.0, 23.0, 11.0, 15.0, 8.0, 8.0, 6.0, 6.0, 19.0, 8.0, 6.0, 11.0, 5.0, 5.0, 3.0, 3.0, 6.0, 5.0, 7.0, 10.0, 5.0, 13.0, 4.0, 4.778365961404949, 1.0789261056092028, 1.0789259724970015, 0.6164923881735854, 0.6164923216174848, 0.6164923216174848, 0.6164923216174848, 0.6164923216174848, 0.6164922550613842, 0.6164922550613842, 0.6164922550613842, 0.6164922550613842, 0.6164922550613842, 0.6164922550613842, 0.6164922550613842, 0.6164922550613842, 0.6164922550613842, 0.6164922550613842, 0.6164922550613842, 0.6164922550613842, 0.6164922550613842, 0.6164922550613842, 0.6164922550613842, 0.6164922550613842, 0.6164921885052835, 0.6164921885052835, 0.6164921885052835, 0.6164921885052835, 0.6164921885052835, 0.6164921885052835, 1.5414097401203066, 1.5414093407837028, 1.0789695001868258, 1.0789691674063226, 1.0789689677380205, 1.0789689677380205, 17.727649756269745, 18.18987601833964, 2.005021833317913, 2.00409124591864, 1.079010565300926, 1.0789989845394132, 2.4675881970621236, 1.541612336890682, 2.466765031209298, 2.004375041131807, 1.5413715369185341, 2.004089515460023, 1.5421756677265746, 2.4669266294216734, 1.0789484684590207, 1.0789484684590207, 1.0789484684590207, 1.0789484684590207, 1.0789482687907188, 1.0789482687907188, 1.0789479360102157, 1.5415053146808386, 2.4664069593878066, 1.5415572284393446, 2.0037049543104737, 1.541638293769935, 2.0035347038050135, 2.0037539396005513, 1.541766081483181, 1.541317360252606, 1.5413052470422879, 1.5413221522918528, 1.541320421833236, 1.0799652460086344, 1.0794927642501275, 1.079305009490197, 1.926605779089704, 1.9266055668316124, 1.926605779089704, 1.926605354573521, 1.9266055668316124, 1.926605354573521, 1.3485852870352724, 1.3485852870352724, 1.3485852870352724, 1.3485852870352724, 1.3485852870352724, 1.3485850747771808, 1.3485850747771808, 1.3485850747771808, 1.3485850747771808, 1.3485850747771808, 1.3485850747771808, 1.3485850747771808, 1.3485850747771808, 1.348584968648135, 1.3485848625190893, 1.3485848625190893, 1.348584968648135, 1.3485848625190893, 1.3485848625190893, 1.3485848625190893, 1.3485846502609977, 1.3485846502609977, 1.3485846502609977, 9.441965835614116, 3.082686030945507, 23.88756298247751, 5.9728510012256315, 20.997236059273522, 1.9266647868391598, 1.9266630887744274, 4.81663702677214, 4.816742306785558, 2.5046433579205067, 2.505361002528098, 1.9267259171695315, 4.2384408911469365, 4.816808531310127, 2.504731657286599, 3.083492187177282, 3.0825236535054574, 1.9266316745768752, 1.9267021442632757, 1.9266938661977047, 2.504562063071436, 2.504527677260602, 1.9265892229585617, 1.926616604252374, 2.5045550585544145, 2.504326881105979, 2.504309688200562, 2.5045467804888433, 2.5040897888176974, 1.927123476575038, 1.9268861720286652, 1.9268649462195084, 1.9268343810543227, 1.9267102100707554, 12.70800424283175, 7.735151902497751, 6.906334935715696, 6.0775333316207, 6.07753258222133, 5.248721985333909, 5.248710744343379, 12.708674205867354, 4.419912887245225, 4.419912887245225, 4.419912887245225, 4.419912887245225, 4.419912887245225, 4.419912887245225, 4.419912887245225, 4.419912887245225, 4.419912137845857, 4.419912137845857, 4.419899398056589, 10.221883078207807, 10.221882328808437, 3.591101540958435, 3.591101166258751, 3.591101166258751, 3.591101166258751, 3.591101166258751, 3.591101166258751, 3.591101166258751, 3.591101166258751, 3.5911007915590667, 20.99656209952528, 7.735618028905074, 6.906677411227186, 6.906603970089055, 19.33974950766925, 6.07772929955561, 6.07772929955561, 6.077728550156242, 111.33985892747599, 103.05176569839104, 18.510540605017372, 8.56451967781579, 20.167961709160775, 14.366450525311516, 10.222083167839244, 8.56433157857425, 15.19478862589698, 11.050849924863599, 7.735509365996615, 8.564718268648493, 10.222030709883438, 10.221530860504524, 11.879039644374064, 9.39303238845416, 6.906487813186908, 10.22045547241046, 9.39332315540921, 7.735017010611388, 10.221213864571569, 8.564231159058847, 7.734962304457474], \"Total\": [153.0, 141.0, 12.0, 5.0, 18.0, 17.0, 15.0, 10.0, 23.0, 11.0, 15.0, 8.0, 8.0, 6.0, 6.0, 19.0, 8.0, 6.0, 11.0, 5.0, 5.0, 3.0, 3.0, 6.0, 5.0, 7.0, 10.0, 5.0, 13.0, 4.0, 5.24732231503547, 1.5478746283071565, 1.5478746068735503, 1.0854397556371744, 1.0854396515842066, 1.0854396921946048, 1.0854397054607356, 1.0854397062727417, 1.0854396787030272, 1.0854396990082265, 1.0854397161998943, 1.0854397224269565, 1.0854397224269565, 1.0854397224269565, 1.0854397263524938, 1.0854397458456868, 1.085439748959218, 1.0854397622253487, 1.0854397661508859, 1.085439769264417, 1.0854397731899543, 1.0854397864560852, 1.0854397864560852, 1.0854398138003525, 1.0854397089353789, 1.0854397151624413, 1.085439729240578, 1.085439729240578, 1.085439729240578, 1.0854397596983767, 3.667469099248415, 3.6674695156418333, 2.376211017780257, 2.3762111782826087, 2.3762113665801214, 2.3762114329107753, 141.7766515139343, 153.41729792829312, 6.364588266196714, 6.365414704733629, 2.7037735382994423, 2.703776228646563, 10.796161412740556, 5.074179937593763, 11.549782720376445, 8.349891504811097, 5.32513255414268, 8.851940795893135, 6.153301623069543, 15.191928882320976, 3.2050605971599917, 3.205060729821299, 3.2050607430874294, 3.2050608641066183, 3.205060969559323, 3.205061107092666, 3.205061399444319, 6.481048727499625, 17.504363130744935, 7.5607134963407425, 15.38457314014146, 8.64016289327792, 23.19278250994408, 23.26929351851361, 10.046946400895209, 11.530457723636385, 13.438955283557476, 17.83387200888659, 22.555950815668304, 4.359838628888067, 5.440195191565735, 5.189449515285048, 2.357025965712707, 2.357025708455819, 2.357025982351732, 2.3570256866271846, 2.357026062816388, 2.3570259559312023, 1.7790048684713782, 1.7790049153088388, 1.7790049220885438, 1.7790049448867988, 1.7790049590666843, 1.7790046820911565, 1.7790048891596388, 1.7790049298378696, 1.7790049427768044, 1.7790049501769847, 1.7790049532566, 1.7790049809958954, 1.7790050302924956, 1.7790049001242445, 1.7790047736560832, 1.7790048069341338, 1.77900494758218, 1.779004840832659, 1.7790048839700296, 1.7790048876701197, 1.7790047247086285, 1.779004771546089, 1.7790048085242294, 12.819666254294487, 5.9990686782846385, 153.41729792829312, 18.006045623015304, 141.7766515139343, 3.185370596304896, 3.1853712838710364, 15.38457314014146, 17.504363130744935, 5.421059282654879, 5.883088984846641, 3.647730059313619, 19.587384178318047, 26.063256343698715, 6.712307238587245, 10.796161412740556, 11.530457723636385, 4.014217706033319, 4.476595341960965, 4.476596453451476, 9.661210285663753, 9.66121806552169, 4.843055803670223, 4.938986438530869, 12.976439808458258, 13.438955283557476, 13.709311462343038, 15.191928882320976, 22.555950815668304, 5.3051351841545635, 8.253937568346469, 6.962949233431862, 6.596359090275691, 8.254144474027399, 13.054830681220729, 8.081975489787048, 7.2531619875029465, 6.424355590042454, 6.424355251216796, 5.595544396428891, 5.595539447659991, 13.632927874312546, 4.766733617131135, 4.766733630622713, 4.766733706170261, 4.76673375361623, 4.766733859745276, 4.766734015565951, 4.766734118547549, 4.766734154747599, 4.766733471678885, 4.76673361558611, 4.766728526791173, 11.030891311075353, 11.030891103107425, 3.9379217132159603, 3.937921468255583, 3.937921536831896, 3.937921629920258, 3.937921637567835, 3.937921660050861, 3.937921747069775, 3.9379217733765897, 3.937921491765268, 23.19278250994408, 8.660009331869578, 7.831158914455885, 7.831136280343952, 23.26929351851361, 6.8867946607433135, 6.886795163729046, 6.886794389375545, 153.41729792829312, 141.7766515139343, 22.555950815668304, 9.951211152551036, 26.063256343698715, 17.83387200888659, 12.186865472019857, 10.066815358315042, 19.587384178318047, 13.709311462343038, 9.122335957541488, 10.413695053228093, 13.227283960324822, 13.227092296746516, 18.006045623015304, 12.976439808458258, 8.29343763759674, 15.191928882320976, 13.438955283557476, 10.046946400895209, 17.504363130744935, 15.38457314014146, 11.549782720376445], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.7845, -6.2727, -6.2727, -6.8323, -6.8323, -6.8323, -6.8323, -6.8323, -6.8323, -6.8323, -6.8323, -6.8323, -6.8323, -6.8323, -6.8323, -6.8323, -6.8323, -6.8323, -6.8323, -6.8323, -6.8323, -6.8323, -6.8323, -6.8323, -6.8323, -6.8323, -6.8323, -6.8323, -6.8323, -6.8323, -5.9159, -5.9159, -6.2726, -6.2726, -6.2726, -6.2726, -3.4735, -3.4478, -5.653, -5.6534, -6.2726, -6.2726, -5.4454, -5.9158, -5.4457, -5.6533, -5.916, -5.6534, -5.9154, -5.4457, -6.2726, -6.2726, -6.2726, -6.2726, -6.2726, -6.2726, -6.2726, -5.9159, -5.4459, -5.9158, -5.6536, -5.9158, -5.6537, -5.6536, -5.9157, -5.916, -5.916, -5.916, -5.916, -6.2717, -6.2721, -6.2723, -6.1595, -6.1595, -6.1595, -6.1595, -6.1595, -6.1595, -6.5162, -6.5162, -6.5162, -6.5162, -6.5162, -6.5162, -6.5162, -6.5162, -6.5162, -6.5162, -6.5162, -6.5162, -6.5162, -6.5162, -6.5162, -6.5162, -6.5162, -6.5162, -6.5162, -6.5162, -6.5162, -6.5162, -6.5162, -4.5701, -5.6894, -3.6419, -5.028, -3.7709, -6.1595, -6.1595, -5.2432, -5.2431, -5.8971, -5.8968, -6.1594, -5.3711, -5.2431, -5.8971, -5.6892, -5.6895, -6.1595, -6.1594, -6.1594, -5.8971, -5.8971, -6.1595, -6.1595, -5.8971, -5.8972, -5.8972, -5.8971, -5.8973, -6.1592, -6.1593, -6.1594, -6.1594, -6.1594, -5.5345, -6.0309, -6.1443, -6.2721, -6.2721, -6.4187, -6.4187, -5.5344, -6.5906, -6.5906, -6.5906, -6.5906, -6.5906, -6.5906, -6.5906, -6.5906, -6.5906, -6.5906, -6.5906, -5.7522, -5.7522, -6.7983, -6.7983, -6.7983, -6.7983, -6.7983, -6.7983, -6.7983, -6.7983, -6.7983, -5.0324, -6.0309, -6.1442, -6.1442, -5.1146, -6.2721, -6.2721, -6.2721, -3.3641, -3.4415, -5.1584, -5.9291, -5.0726, -5.4118, -5.7522, -5.9291, -5.3558, -5.6742, -6.0309, -5.9291, -5.7522, -5.7522, -5.6019, -5.8367, -6.1443, -5.7523, -5.8367, -6.031, -5.7523, -5.9291, -6.031], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 2.0135, 1.7462, 1.7462, 1.5414, 1.5414, 1.5414, 1.5414, 1.5414, 1.5414, 1.5414, 1.5414, 1.5414, 1.5414, 1.5414, 1.5414, 1.5414, 1.5414, 1.5414, 1.5414, 1.5414, 1.5414, 1.5414, 1.5414, 1.5414, 1.5414, 1.5414, 1.5414, 1.5414, 1.5414, 1.5414, 1.2403, 1.2403, 1.3176, 1.3176, 1.3176, 1.3176, 0.028, -0.0252, 0.952, 0.9514, 1.1885, 1.1885, 0.6312, 0.9158, 0.5633, 0.6802, 0.8673, 0.6217, 0.7233, 0.2893, 1.0184, 1.0184, 1.0184, 1.0184, 1.0184, 1.0184, 1.0184, 0.671, 0.1474, 0.5169, 0.0687, 0.3835, -0.3418, -0.345, 0.2328, 0.0948, -0.0584, -0.3414, -0.5763, 0.7116, 0.4898, 0.5368, 1.4389, 1.4389, 1.4389, 1.4389, 1.4389, 1.4389, 1.3635, 1.3635, 1.3635, 1.3635, 1.3635, 1.3635, 1.3635, 1.3635, 1.3635, 1.3635, 1.3635, 1.3635, 1.3635, 1.3635, 1.3635, 1.3635, 1.3635, 1.3635, 1.3635, 1.3635, 1.3635, 1.3635, 1.3635, 1.3347, 0.9747, -0.2193, 0.537, -0.2694, 1.1377, 1.1377, 0.4792, 0.3501, 0.8684, 0.7868, 1.0022, 0.1098, -0.0479, 0.6547, 0.3874, 0.3213, 0.9064, 0.7974, 0.7974, 0.2905, 0.2905, 0.7187, 0.6991, -0.0045, -0.0396, -0.0596, -0.1622, -0.5576, 0.6278, 0.1857, 0.3558, 0.4099, 0.1856, 0.3521, 0.3352, 0.33, 0.3235, 0.3235, 0.315, 0.315, 0.3088, 0.3035, 0.3035, 0.3035, 0.3035, 0.3035, 0.3035, 0.3035, 0.3035, 0.3035, 0.3035, 0.3035, 0.3029, 0.3029, 0.2868, 0.2868, 0.2868, 0.2868, 0.2868, 0.2868, 0.2868, 0.2868, 0.2868, 0.2795, 0.2661, 0.2534, 0.2534, 0.1941, 0.2541, 0.2541, 0.2541, 0.0585, 0.06, 0.1814, 0.229, 0.1226, 0.1628, 0.2032, 0.2174, 0.1251, 0.1635, 0.2141, 0.1836, 0.1213, 0.1213, -0.0369, 0.0559, 0.196, -0.0173, 0.0209, 0.1175, -0.159, -0.2067, -0.0219]}, \"token.table\": {\"Topic\": [1, 2, 3, 1, 1, 3, 1, 2, 3, 1, 2, 3, 1, 1, 1, 1, 1, 3, 1, 1, 2, 3, 1, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 2, 2, 1, 2, 3, 2, 1, 2, 3, 2, 1, 3, 3, 2, 3, 2, 2, 3, 2, 3, 3, 1, 3, 1, 2, 3, 3, 1, 1, 3, 1, 2, 3, 3, 1, 2, 3, 2, 3, 2, 1, 1, 1, 1, 3, 1, 1, 2, 3, 1, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 2, 2, 2, 3, 3, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 3, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 2, 1, 3, 1, 2, 3, 1, 3, 1, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 3, 3, 1, 2, 3, 3, 2, 3, 2, 2, 1, 3, 1, 1, 3, 2, 1, 3, 1, 2, 1, 3, 2, 3, 2, 1, 2, 3, 3, 3, 3, 1, 2, 2, 3, 3, 1, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 2, 3, 3, 2, 2, 3, 1, 2, 3, 3, 1, 3, 1, 1, 3, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 3, 1, 1, 2, 3, 1, 2, 1, 2, 3, 1, 1, 2, 3, 2, 1, 3, 1, 2, 3, 2, 2, 3, 1, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 3, 1, 2, 3, 1, 3, 2, 3, 1], \"Freq\": [0.12115429656688478, 0.24230859313376957, 0.605771482834424, 0.9212856266644874, 0.42083797180246507, 0.42083797180246507, 0.31423870898645573, 0.15711935449322786, 0.6284774179729115, 0.2233839950503011, 0.4467679901006022, 0.4467679901006022, 0.9212856328303698, 0.9212856182386459, 0.9212856071701416, 0.9212855731992222, 0.1452054222937745, 0.871232533762647, 0.9212856129533199, 0.3141979105481853, 0.15709895527409265, 0.6283958210963706, 0.9212855930762706, 1.0157642452404172, 0.08205555417805556, 0.08205555417805556, 0.8205555417805556, 0.9212856071701416, 0.11425722747302751, 0.2856430686825688, 0.5712861373651376, 0.19906545931426436, 0.09953272965713218, 0.7962618372570575, 0.8485269212028338, 0.5621119892518428, 0.1488210919525117, 0.22323163792876755, 0.6696949137863026, 0.562111982825295, 0.17345365187890008, 0.2601804778183501, 0.6070877815761503, 0.5621119986404538, 0.09065450576926358, 0.9065450576926357, 1.0157642712246742, 0.5621119730874476, 0.8391490288219777, 0.5621120386005888, 0.4982290813460428, 0.4982290813460428, 0.562112008641807, 0.9650963279271662, 0.8391489827076251, 0.5453351395205764, 0.5453351395205764, 0.10049028049652486, 0.10049028049652486, 0.9044125244687238, 1.0157642169950223, 0.9212856500647576, 0.31200655538213656, 0.6240131107642731, 0.19269866621779277, 0.19269866621779277, 0.5780959986533784, 1.0157642257274186, 0.9212856730823249, 0.11547331667645139, 0.9237865334116111, 0.5621119575112077, 1.0157642889135412, 0.5621120675323551, 0.6460471640011163, 0.9212855698673553, 0.9212855586075, 0.31200656716312397, 0.6240131343262479, 0.9212856273536916, 0.12696025620432216, 0.14812029890504255, 0.7264947993913992, 0.9212855904336076, 0.31200654511651743, 0.6240130902330349, 0.23952407032446188, 0.23952407032446188, 0.47904814064892376, 0.08595018144443242, 0.08595018144443242, 0.816526723722108, 0.9212856129533199, 0.5621120275833028, 1.0157642828493525, 0.8391490371744977, 0.5621119800164177, 0.5621120037446995, 0.3332214149413688, 0.6664428298827376, 0.9339458615498542, 0.553397379290565, 0.553397379290565, 0.18525102798479828, 0.2778765419771974, 0.46312756996199567, 0.31200650326804225, 0.6240130065360845, 0.14898006966237623, 0.4469402089871287, 0.5959202786495049, 0.9339458122928015, 0.5621120173748106, 0.8935688947901098, 0.2741430927562021, 0.5482861855124042, 0.2741430927562021, 0.26452529922843476, 0.13226264961421738, 0.6613132480710868, 0.8485268922356417, 0.3120065813688831, 0.6240131627377662, 0.18849661041377627, 0.37699322082755254, 0.5654898312413288, 0.11214614521195415, 0.11214614521195415, 0.785023016483679, 0.14520543289903562, 0.8712325973942138, 0.16997873099926736, 0.5099361929978021, 0.5099361929978021, 0.5621120025755824, 0.5453352014362891, 0.5453352014362891, 0.03836819109680318, 0.1918409554840159, 0.7673638219360636, 0.4208380453240017, 0.4208380453240017, 0.6460471550552235, 0.9212856244045283, 0.10350670055116155, 0.31052010165348465, 0.6210402033069693, 0.11732705661660889, 0.15643607548881183, 0.7235168491357548, 0.07800515084899405, 0.7020463576409465, 0.23401545254698214, 0.5621119844968344, 0.14520543862072152, 0.8712326317243291, 0.17316343072597762, 0.08658171536298881, 0.6926537229039105, 0.12115125960620308, 0.24230251921240617, 0.6057562980310154, 0.5621119851635291, 0.18381693391265827, 0.18381693391265827, 0.7352677356506331, 0.10962104494444697, 0.10962104494444697, 0.8769683595555757, 0.1316488521959462, 0.19747327829391928, 0.6582442609797309, 0.41296241073339185, 0.6194436161000878, 0.8391490504740982, 0.07560131036722999, 0.15120262073445997, 0.7560131036722999, 0.8935681045066909, 0.204213077335142, 0.7657990400067824, 0.8485270198050913, 0.5621120392672836, 0.08623372375188207, 0.9054540993947617, 0.9212855353985867, 0.31200656845455654, 0.6240131369091131, 0.8485269307141973, 0.32502876057655533, 0.6500575211531107, 0.36985346066703395, 0.36985346066703395, 0.09065450747839382, 0.9065450747839383, 0.12769538981335143, 0.8938677286934601, 0.8485269271928657, 0.10350661720065436, 0.3105198516019631, 0.6210397032039262, 0.8391489645784612, 1.01576423944105, 1.0157642102093312, 0.9212856129533199, 0.8485270276633791, 0.21882937069745984, 0.8023743592240195, 0.8391490784550129, 0.9212855813185628, 0.3698530926505604, 0.3698530926505604, 0.8391490531211835, 0.42083801689828915, 0.42083801689828915, 0.2293662874066144, 0.2293662874066144, 0.4587325748132288, 0.2024706967984941, 0.4049413935969882, 0.4049413935969882, 0.08866839692746256, 0.13300259539119383, 0.8423497708108943, 0.8391499489677645, 0.6278702925862668, 0.3139351462931334, 0.8391490528491931, 0.5621120280857252, 0.6278704281128377, 0.31393521405641883, 0.15159878143598846, 0.3031975628719769, 0.6063951257439538, 0.8391489582057051, 0.9212855758418851, 0.8391490101387266, 0.9212856096214527, 0.31200653172791054, 0.6240130634558211, 0.12769502074004085, 0.8938651451802859, 0.9212856386135485, 0.5621119917003965, 0.07706273945402062, 0.23118821836206188, 0.6935646550861856, 0.22338405051414625, 0.4467681010282925, 0.4467681010282925, 0.9212856071701416, 0.07560240584742658, 0.15120481169485317, 0.7560240584742659, 0.9898569984664469, 0.921285619119202, 0.9212855586075, 0.09933628107860493, 0.8940265297074443, 0.9212855847655776, 0.5621120021049392, 0.3941523604991478, 0.1970761802495739, 0.5912285407487217, 0.921285579173752, 0.20247069159749626, 0.4049413831949925, 0.4049413831949925, 0.5621120540665138, 0.42083798354992924, 0.42083798354992924, 0.3085920325693332, 0.1542960162846666, 0.6171840651386664, 0.5621119938425791, 0.07335181475464425, 0.9535735918103754, 0.3755775052855919, 0.7511550105711838, 0.12057726164922106, 0.12057726164922106, 0.8440408315445475, 0.5000776221914855, 0.5000776221914855, 0.1436173044603867, 0.2872346089207734, 0.5744692178415468, 0.22593915234136017, 0.11296957617068008, 0.6778174570240805, 0.5621119836451751, 0.09602739420432853, 0.09602739420432853, 0.8642465478389567, 1.015764247213066, 0.13000035696678486, 0.3250008924169621, 0.5850016063505318, 0.23147711735342488, 0.8101699107369871, 0.5621119818522293, 0.9957999699452554, 0.9528669480952594], \"Term\": [\"10\", \"10\", \"10\", \"2\", \"25\", \"25\", \"3\", \"3\", \"3\", \"30\", \"30\", \"30\", \"4000\", \"5000\", \"65\", \"7\", \"70\", \"70\", \"985\", \"able\", \"able\", \"able\", \"abundant\", \"according\", \"adult\", \"adult\", \"adult\", \"advertisement\", \"also\", \"also\", \"also\", \"although\", \"although\", \"although\", \"ancient\", \"and\", \"animal\", \"animal\", \"animal\", \"appetite\", \"around\", \"around\", \"around\", \"asexually\", \"attack\", \"attack\", \"attempt\", \"attributed\", \"auffenberg\", \"avid\", \"avoid\", \"avoid\", \"beast\", \"become\", \"behavior\", \"behaviour\", \"behaviour\", \"bite\", \"bite\", \"bite\", \"bronstein\", \"cannot\", \"capable\", \"capable\", \"carrion\", \"carrion\", \"carrion\", \"case\", \"centimetre\", \"chromosome\", \"chromosome\", \"clear\", \"could\", \"cover\", \"dangerous\", \"deeplyforked\", \"destruction\", \"detect\", \"detect\", \"dosed\", \"dragon\", \"dragon\", \"dragon\", \"drinking\", \"ear\", \"ear\", \"eat\", \"eat\", \"eat\", \"egg\", \"egg\", \"egg\", \"enough\", \"established\", \"exhibit\", \"expedition\", \"fact\", \"feces\", \"female\", \"female\", \"first\", \"food\", \"food\", \"foot\", \"foot\", \"foot\", \"form\", \"form\", \"found\", \"found\", \"found\", \"ft\", \"give\", \"habit\", \"habitat\", \"habitat\", \"habitat\", \"head\", \"head\", \"head\", \"home\", \"hour\", \"hour\", \"however\", \"however\", \"however\", \"human\", \"human\", \"human\", \"individual\", \"individual\", \"indonesia\", \"indonesia\", \"indonesia\", \"inhabit\", \"insect\", \"insect\", \"island\", \"island\", \"island\", \"kilogram\", \"kilogram\", \"kilometre\", \"knock\", \"known\", \"known\", \"known\", \"komodo\", \"komodo\", \"komodo\", \"komodos\", \"komodos\", \"komodos\", \"kraken\", \"laid\", \"laid\", \"large\", \"large\", \"large\", \"largest\", \"largest\", \"largest\", \"least\", \"length\", \"length\", \"length\", \"live\", \"live\", \"live\", \"lizard\", \"lizard\", \"lizard\", \"local\", \"local\", \"london\", \"long\", \"long\", \"long\", \"make\", \"male\", \"male\", \"massive\", \"mate\", \"may\", \"may\", \"mediumlarge\", \"megapode\", \"megapode\", \"meter\", \"metre\", \"metre\", \"mile\", \"mile\", \"monitor\", \"monitor\", \"mouth\", \"mouth\", \"myth\", \"national\", \"national\", \"national\", \"natural\", \"observation\", \"observed\", \"occurring\", \"old\", \"one\", \"one\", \"osteoderms\", \"particularly\", \"per\", \"per\", \"period\", \"plaque\", \"plaque\", \"pound\", \"pound\", \"pound\", \"predator\", \"predator\", \"predator\", \"prey\", \"prey\", \"prey\", \"produced\", \"protect\", \"protect\", \"protein\", \"rely\", \"reproduce\", \"reproduce\", \"reproduction\", \"reproduction\", \"reproduction\", \"researcher\", \"safety\", \"scientist\", \"season\", \"sensory\", \"sensory\", \"several\", \"several\", \"shaded\", \"sign\", \"size\", \"size\", \"size\", \"smell\", \"smell\", \"smell\", \"smelling\", \"specie\", \"specie\", \"specie\", \"specimen\", \"stocky\", \"strictly\", \"study\", \"study\", \"support\", \"swim\", \"tail\", \"tail\", \"tail\", \"taking\", \"taste\", \"taste\", \"taste\", \"they\\u2019re\", \"throat\", \"throat\", \"tongue\", \"tongue\", \"tongue\", \"truth\", \"two\", \"two\", \"use\", \"use\", \"varanus\", \"varanus\", \"varanus\", \"venom\", \"venom\", \"victim\", \"victim\", \"victim\", \"water\", \"water\", \"water\", \"whether\", \"wild\", \"wild\", \"wild\", \"would\", \"year\", \"year\", \"year\", \"young\", \"young\", \"younger\", \"zoo\", \"\\u2013\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el2464423679823261927119557550\", ldavis_el2464423679823261927119557550_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el2464423679823261927119557550\", ldavis_el2464423679823261927119557550_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el2464423679823261927119557550\", ldavis_el2464423679823261927119557550_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.display(lda_display) #Visualization of the results(works on local jupyter notebook).   It may not be visible over github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Which ML/DL model architecture you used and why?\n",
    "- I am using webscrapping by utilising the yahoo's search engine to get the most relevant articles for the given query.\n",
    "- I have used LDA i.e. <b>Latent Dirichlet Model</b> to train my model primarily because it is currently one of the most popular topic modelling technique.\n",
    "- There are other techniques as well such Term Frequency and Inverse Document Frequency, NonNegative Matrix Factorization techniques which I haven't used for now.\n",
    "\n",
    "##### 2. How would you ensure the scalability of your solution?\n",
    "- j\n",
    "\n",
    "##### 3. Is there a need for any dataset? If yes then how much data is sufficient to train the model in order to get the required results?\n",
    "- We are scrapping the top query relevant articles from the web. So, the result of this webscrapping would be multiple web articles out of which we have to ensure few parameters as follows:\n",
    "    - articles text size\n",
    "    - number of unique words in each article\n",
    "    - total vocabulary size from all the articles\n",
    "    - Permission to scrap the website\n",
    "- Once we make sure that we satisfy the above parameters then we are good to select our top five required articles.\n",
    "\n",
    "##### 4. Is there a need to create manual datasets, if yes then what parameters and sample size did you consider to create a dataset? \n",
    "- No.\n",
    "- If we use potentially strong search engine then we will always get enough number of articles.\n",
    "- Even if the articles on the first page are not sufficient, still we can move over to the next page to webscrap further articles.\n",
    "\n",
    "##### 5. Is your model and dataset generalized enough for different domains of the use cases, How?\n",
    "- Yes. As discussed in the point two, I have considered the parameters sensitive for the possible test cases.\n",
    "- Also the model I have chosed is LDA which is currently the most popular in topic modelling.\n",
    "\n",
    "##### 6. How would you train, test and deploy your model to production? \n",
    "- One of the production effiecint technique which I know is by using GCP's DataFlow Pipeline and AI Platform's tf.estimator API both of which allows us the use of multiple GPUs.\n",
    "- Using DataFlow pipeline we can have even terabytes of data in our articles which will be converted into tfrecords and get stored on the cloud storage.\n",
    "- Once the tfrecords are obtained, we can use AI Platform which allows us to perform 3 operations on the dataset anytime. i.e. i) training ii) evaluation iii) prediction\n",
    "- On AI Platform, we can deploy our model and then our code will run in the prediction mode as per the tf estimator API.\n",
    "\n",
    "##### 7. How would you perform hyperparameter tuning on your model to improve accuracy?\n",
    "- I have provided the solution with the visualization, I have observed that the topics don't get overlap mostly when I set 3 topics.\n",
    "- Possible reason for this could be a less dataset that is getting scrapped becasue we are dealling with only top 5 articles.\n",
    "- Had been the case that we were using more articles, we would have got the freedom to get the results from even more topics.\n",
    "\n",
    "##### 8. Anything else you want to let us know about your approach.\n",
    "- j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <hr>\n",
    "#### Model/Code on GitHub repo or Colab Notebook with the necessary documentation describing the model functioning.\n",
    "- Code is push on my github repo on this url : https://github.com/vishalw-iitk/ML_new/blob/master/CareerNinja/vishal_w.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <hr>\n",
    "#### Only Approach to generate different types of questions (short answer type, MCQs, true/false, fill in the blanks, long answer type, etc.) for that same article.\n",
    "- We can generate questions using <b>allennlp</b> for all the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
